{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "11I95iJBakZ6cNEOgrHiytsutzswQyCrQ",
      "authorship_tag": "ABX9TyPn/mw27v2oCAUWs1p2+mMH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhinanduReddy/Mask-Detection/blob/master/detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAzRBdMT6p5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of training steps.\n",
        "num_steps = 1000000  # 200000\n",
        "\n",
        "# Number of evaluation steps.\n",
        "num_eval_steps = 50\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "        'batch_size':1\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
        "        'batch_size': 8\n",
        "    }\n",
        "}\n",
        "\n",
        "# Pick the model you want to use\n",
        "# Select a model in `MODELS_CONFIG`.\n",
        "selected_model = 'rfcn_resnet101'\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Name of the pipline file in tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn6GVSnp6uKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone --quiet https://github.com/tensorflow/models.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP1CqfyCGB5G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "21facf40-d8f3-4d7b-ed09-85ece02eb22d"
      },
      "source": [
        "#downlaoding ngrok to be able to access tensorboard on google colab\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-22 14:30:26--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.7.103.227, 34.192.78.186, 52.207.93.234, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.7.103.227|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.1’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  12.4MB/s    in 1.1s    \n",
            "\n",
            "2020-04-22 14:30:27 (12.4 MB/s) - ‘ngrok-stable-linux-amd64.zip.1’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp4f9QdMGJCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the logs that are created while training \n",
        "LOG_DIR = model_dir\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZktuncBGKU6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff53947b-0543-4735-dfd5-fd71b7c611ce"
      },
      "source": [
        "#The link to tensorboard.\n",
        "#works after the training starts.\n",
        "\n",
        "### note: if you didnt get a link as output, rerun this cell and the one above\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://c597c530.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpvMSoRO67tk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "07e0e99c-3f58-4c76-a450-88babe5ad9ad"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " a3c_blogpost\t\t\t    lstm_object_detection\n",
            " adversarial_crypto\t\t    marco\n",
            " adversarial_logit_pairing\t    maskgan\n",
            " adversarial_text\t\t    models\n",
            " adv_imagenet_models\t\t    namignizer\n",
            " attention_ocr\t\t\t    neural_gpu\n",
            " audioset\t\t\t    neural_programmer\n",
            " autoaugment\t\t\t    next_frame_prediction\n",
            " autoencoder\t\t\t    ngrok\n",
            " brain_coder\t\t\t    ngrok-stable-linux-amd64.zip\n",
            " cognitive_mapping_and_planning     ngrok-stable-linux-amd64.zip.1\n",
            " cognitive_planning\t\t    nst_blogpost\n",
            " compression\t\t\t    object_detection\n",
            " cvt_text\t\t\t    pcl_rl\n",
            " deep_contextual_bandits\t    pretrained_model\n",
            " deeplab\t\t\t    ptn\n",
            " deep_speech\t\t\t    qa_kg\n",
            " delf\t\t\t\t    README.md\n",
            " domain_adaptation\t\t    real_nvp\n",
            " efficient-hrl\t\t\t    rebar\n",
            " feelvos\t\t\t    sentiment_analysis\n",
            " fine_tuned_modelrcnn\t\t    seq2species\n",
            "'fine_tuned_model ssd'\t\t    setup.py\n",
            " fivo\t\t\t\t    skip_thoughts\n",
            " global_objectives\t\t    slim\n",
            " im2txt\t\t\t\t    steve\n",
            " inception\t\t\t    street\n",
            " keypointnet\t\t\t    struct2depth\n",
            " learned_optimizer\t\t    swivel\n",
            " learning_to_remember_rare_events   tcn\n",
            " learning_unsupervised_learning     textsum\n",
            " lexnet_nc\t\t\t    training\n",
            " lfads\t\t\t\t    transformer\n",
            " lm_1b\t\t\t\t    vid2depth\n",
            " lm_commonsense\t\t\t    video_prediction\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcoqgsBg7Vku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "!pip install -q pycocotools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVh67wJm7cjn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e33a4746-0035-47fd-9e0e-599e013ba3c6"
      },
      "source": [
        "%cd models/research"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqVs36e97nTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIKwB6eb-r3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.15.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6nTbFUE7rF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZRsRBfF7vej",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "18fd801e-4d01-48df-f500-06da3933a914"
      },
      "source": [
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Running tests under Python 3.6.9: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTest.test_create_experimental_model\n",
            "[       OK ] ModelBuilderTest.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_create_ssd_models_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
            "[       OK ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
            "[       OK ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_model_config_proto\n",
            "[       OK ] ModelBuilderTest.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
            "[       OK ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTest.test_session\n",
            "[  SKIPPED ] ModelBuilderTest.test_session\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
            "[       OK ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_meta_architecture\n",
            "[       OK ] ModelBuilderTest.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
            "[       OK ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 17 tests in 0.167s\n",
            "\n",
            "OK (skipped=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFjJCDJFIEFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzMCjhLAGcSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_record_fname = '/content/drive/My Drive/data/test.record'\n",
        "train_record_fname = '/content/drive/My Drive/data/train.record'\n",
        "label_map_pbtxt_fname = '/content/drive/My Drive/data/object-detection.pbtxt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzpY-WdzQ4d4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xq1aGNazQ9tY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "60536df3-c859-4701-fe01-3485b5c92e6d"
      },
      "source": [
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/pretrained_model\n",
            "total 476M\n",
            "drwxr-xr-x  3 345018 5000 4.0K Feb  1  2018 .\n",
            "drwxr-xr-x 68 root   root 4.0K Apr 22 14:32 ..\n",
            "-rw-r--r--  1 345018 5000   77 Feb  1  2018 checkpoint\n",
            "-rw-r--r--  1 345018 5000 208M Feb  1  2018 frozen_inference_graph.pb\n",
            "-rw-r--r--  1 345018 5000 262M Feb  1  2018 model.ckpt.data-00000-of-00001\n",
            "-rw-r--r--  1 345018 5000  26K Feb  1  2018 model.ckpt.index\n",
            "-rw-r--r--  1 345018 5000 6.4M Feb  1  2018 model.ckpt.meta\n",
            "-rw-r--r--  1 345018 5000 3.1K Feb  1  2018 pipeline.config\n",
            "drwxr-xr-x  3 345018 5000 4.0K Feb  1  2018 saved_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKhKMSnDRBRN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "743f9987-f543-47bb-8de2-95764ed4915c"
      },
      "source": [
        "\n",
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "fine_tune_checkpoint"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/models/research/pretrained_model/model.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDwZGjVvRExx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLpA-m0WRHYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zalhn44HRJ_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    f.write(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9uj-qjARMdv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "129aa95f-6f26-4344-dafb-eb2a9f50c02a"
      },
      "source": [
        "!cat {pipeline_fname}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "model {\n",
            "  faster_rcnn {\n",
            "    num_classes: 2\n",
            "    image_resizer {\n",
            "      keep_aspect_ratio_resizer {\n",
            "        min_dimension: 600\n",
            "        max_dimension: 1024\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'faster_rcnn_resnet101'\n",
            "      first_stage_features_stride: 16\n",
            "    }\n",
            "    first_stage_anchor_generator {\n",
            "      grid_anchor_generator {\n",
            "        scales: [0.25, 0.5, 1.0, 2.0]\n",
            "        aspect_ratios: [0.5, 1.0, 2.0]\n",
            "        height_stride: 16\n",
            "        width_stride: 16\n",
            "      }\n",
            "    }\n",
            "    first_stage_box_predictor_conv_hyperparams {\n",
            "      op: CONV\n",
            "      regularizer {\n",
            "        l2_regularizer {\n",
            "          weight: 0.0\n",
            "        }\n",
            "      }\n",
            "      initializer {\n",
            "        truncated_normal_initializer {\n",
            "          stddev: 0.01\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    first_stage_nms_score_threshold: 0.0\n",
            "    first_stage_nms_iou_threshold: 0.7\n",
            "    first_stage_max_proposals: 300\n",
            "    first_stage_localization_loss_weight: 2.0\n",
            "    first_stage_objectness_loss_weight: 1.0\n",
            "    second_stage_box_predictor {\n",
            "      rfcn_box_predictor {\n",
            "        conv_hyperparams {\n",
            "          op: CONV\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.0\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            truncated_normal_initializer {\n",
            "              stddev: 0.01\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        crop_height: 18\n",
            "        crop_width: 18\n",
            "        num_spatial_bins_height: 3\n",
            "        num_spatial_bins_width: 3\n",
            "      }\n",
            "    }\n",
            "    second_stage_post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 0.0\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 300\n",
            "      }\n",
            "      score_converter: SOFTMAX\n",
            "    }\n",
            "    second_stage_localization_loss_weight: 2.0\n",
            "    second_stage_classification_loss_weight: 1.0\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  batch_size: 8\n",
            "  optimizer {\n",
            "    momentum_optimizer: {\n",
            "      learning_rate: {\n",
            "        manual_step_learning_rate {\n",
            "          initial_learning_rate: 0.0003\n",
            "          schedule {\n",
            "            step: 900000\n",
            "            learning_rate: .00003\n",
            "          }\n",
            "          schedule {\n",
            "            step: 1200000\n",
            "            learning_rate: .000003\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "    }\n",
            "    use_moving_average: false\n",
            "  }\n",
            "  gradient_clipping_by_norm: 10.0\n",
            "  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n",
            "  from_detection_checkpoint: true\n",
            "  load_all_detection_checkpoint_vars: true\n",
            "  # Note: The below line limits the training process to 200K steps, which we\n",
            "  # empirically found to be sufficient enough to train the pets dataset. This\n",
            "  # effectively bypasses the learning rate schedule (the learning rate will\n",
            "  # never decay). Remove the below line to train indefinitely.\n",
            "  num_steps: 1000000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    random_vertical_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    random_pad_image{\n",
            "    }\n",
            "  }\n",
            "  \n",
            "}\n",
            "\n",
            "train_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/drive/My Drive/data/train.record\"\n",
            "  }\n",
            "  label_map_path: \"/content/drive/My Drive/data/object-detection.pbtxt\"\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  metrics_set: \"coco_detection_metrics\"\n",
            "  num_examples: 1101\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/drive/My Drive/data/test.record\"\n",
            "  }\n",
            "  label_map_path: \"/content/drive/My Drive/data/object-detection.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_readers: 1\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g7vWL3INFdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdjJbuzbRRvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dir = 'training/'\n",
        "# Optionally remove content in output model directory to fresh start.\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP3JGarqRabL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fdc3929b-f783-4904-fa94-b798cff404ee"
      },
      "source": [
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_main.py:109: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0422 14:33:35.217503 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:628: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "W0422 14:33:35.220001 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:628: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0422 14:33:35.220142 140600397518720 model_lib.py:629] Forced number of epochs for all eval validations to be 1.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0422 14:33:35.220259 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 1000000\n",
            "I0422 14:33:35.220369 140600397518720 config_util.py:488] Maybe overwriting train_steps: 1000000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0422 14:33:35.220454 140600397518720 config_util.py:488] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0422 14:33:35.220534 140600397518720 config_util.py:488] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0422 14:33:35.220606 140600397518720 config_util.py:488] Maybe overwriting eval_num_epochs: 1\n",
            "INFO:tensorflow:Maybe overwriting load_pretrained: True\n",
            "I0422 14:33:35.220691 140600397518720 config_util.py:488] Maybe overwriting load_pretrained: True\n",
            "INFO:tensorflow:Ignoring config override key: load_pretrained\n",
            "I0422 14:33:35.220760 140600397518720 config_util.py:498] Ignoring config override key: load_pretrained\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0422 14:33:35.221383 140600397518720 model_lib.py:645] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "I0422 14:33:35.221482 140600397518720 model_lib.py:680] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdfac920940>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0422 14:33:35.221856 140600397518720 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdfac920940>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fdfac983730>) includes params argument, but params are not passed to Estimator.\n",
            "W0422 14:33:35.222059 140600397518720 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fdfac983730>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0422 14:33:35.222822 140600397518720 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0422 14:33:35.223000 140600397518720 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0422 14:33:35.223227 140600397518720 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0422 14:33:35.228120 140600397518720 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0422 14:33:35.237538 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
            "\n",
            "W0422 14:33:35.237798 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0422 14:33:35.252478 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0422 14:33:35.253758 140600397518720 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W0422 14:33:35.259473 140600397518720 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0422 14:33:35.259621 140600397518720 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0422 14:33:35.279139 140600397518720 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:Entity <function build.<locals>.process_fn at 0x7fdfac983ae8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0422 14:33:35.295540 140600397518720 ag_logging.py:146] Entity <function build.<locals>.process_fn at 0x7fdfac983ae8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:491: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
            "\n",
            "W0422 14:33:35.436084 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/utils/ops.py:491: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0422 14:33:35.439824 140600397518720 deprecation.py:323] From /content/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:627: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0422 14:33:35.484999 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/core/preprocessor.py:627: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:2689: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W0422 14:33:35.699520 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/core/preprocessor.py:2689: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:168: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0422 14:33:35.733213 140600397518720 deprecation.py:323] From /content/models/research/object_detection/inputs.py:168: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:470: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\n",
            "\n",
            "W0422 14:33:35.999391 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/inputs.py:470: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "W0422 14:33:36.020294 140600397518720 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0422 14:33:36.032000 140600397518720 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:168: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0422 14:33:36.140242 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:168: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0422 14:33:36.148181 140600397518720 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0422 14:33:36.151553 140600397518720 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "W0422 14:33:38.994890 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0422 14:33:39.001106 140600397518720 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:558: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "W0422 14:33:39.001477 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:558: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0422 14:33:39.014268 140600397518720 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0422 14:33:39.014584 140600397518720 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0422 14:33:39.708819 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/minibatch_sampler.py:85: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
            "\n",
            "W0422 14:33:39.744700 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/core/minibatch_sampler.py:85: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:191: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W0422 14:33:41.551346 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:191: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0422 14:33:41.551715 140600397518720 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0422 14:33:41.811218 140600397518720 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:766: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "W0422 14:33:41.912964 140600397518720 deprecation.py:506] From /content/models/research/object_detection/utils/ops.py:766: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "W0422 14:33:43.972124 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2768: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0422 14:33:43.972427 140600397518720 deprecation.py:323] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2768: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
            "\n",
            "W0422 14:33:43.973982 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/variables_helper.py:142: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "W0422 14:33:43.975884 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/utils/variables_helper.py:142: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "W0422 14:33:43.980425 140600397518720 variables_helper.py:154] Variable [SecondStageBoxPredictor/class_predictions/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[819]], model variable shape: [[27]]. This variable will not be initialized from the checkpoint.\n",
            "W0422 14:33:43.980539 140600397518720 variables_helper.py:154] Variable [SecondStageBoxPredictor/class_predictions/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 1024, 819]], model variable shape: [[1, 1, 1024, 27]]. This variable will not be initialized from the checkpoint.\n",
            "W0422 14:33:43.980643 140600397518720 variables_helper.py:154] Variable [SecondStageBoxPredictor/refined_locations/biases] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[3240]], model variable shape: [[72]]. This variable will not be initialized from the checkpoint.\n",
            "W0422 14:33:43.980712 140600397518720 variables_helper.py:154] Variable [SecondStageBoxPredictor/refined_locations/weights] is available in checkpoint, but has an incompatible shape with model variable. Checkpoint shape: [[1, 1, 1024, 3240]], model variable shape: [[1, 1, 1024, 72]]. This variable will not be initialized from the checkpoint.\n",
            "W0422 14:33:43.981128 140600397518720 variables_helper.py:157] Variable [global_step] is not available in checkpoint\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:353: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "W0422 14:33:43.981352 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:353: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
            "\n",
            "W0422 14:33:46.903030 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
            "\n",
            "W0422 14:33:46.904180 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:350: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "W0422 14:33:46.949178 140600397518720 deprecation.py:323] From /content/models/research/object_detection/core/losses.py:350: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2710: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "W0422 14:33:48.067286 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2710: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:380: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0422 14:33:48.068160 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:380: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/optimizer_builder.py:58: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
            "\n",
            "W0422 14:33:48.074776 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/builders/optimizer_builder.py:58: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:398: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "W0422 14:33:48.074981 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:398: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:408: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W0422 14:33:48.075150 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:408: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:515: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0422 14:34:00.365324 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:515: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:519: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "W0422 14:34:01.170538 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:519: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:520: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
            "\n",
            "W0422 14:34:01.170812 140600397518720 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:520: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0422 14:34:01.171112 140600397518720 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0422 14:34:01.172254 140600397518720 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0422 14:34:05.644793 140600397518720 monitored_session.py:240] Graph was finalized.\n",
            "2020-04-22 14:34:05.645184: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
            "2020-04-22 14:34:05.649596: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000179999 Hz\n",
            "2020-04-22 14:34:05.649781: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x22f5a300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-04-22 14:34:05.649810: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-04-22 14:34:05.668726: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-04-22 14:34:05.759776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-22 14:34:05.760457: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x22f5a140 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-04-22 14:34:05.760494: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-04-22 14:34:05.760756: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-22 14:34:05.761241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-04-22 14:34:05.761709: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-22 14:34:05.763462: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-04-22 14:34:05.765353: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-04-22 14:34:05.765825: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-04-22 14:34:05.769417: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-04-22 14:34:05.771813: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-04-22 14:34:05.775920: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-22 14:34:05.776036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-22 14:34:05.776546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-22 14:34:05.776968: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-04-22 14:34:05.777032: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-22 14:34:05.778133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-04-22 14:34:05.778158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-04-22 14:34:05.778168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-04-22 14:34:05.778377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-22 14:34:05.778840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-22 14:34:05.779267: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-04-22 14:34:05.779322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10329 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0422 14:34:11.409084 140600397518720 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0422 14:34:11.958747 140600397518720 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.\n",
            "I0422 14:34:25.868602 140600397518720 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n",
            "2020-04-22 14:34:55.129586: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 87326796 exceeds 10% of system memory.\n",
            "2020-04-22 14:34:55.542123: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 87326796 exceeds 10% of system memory.\n",
            "2020-04-22 14:34:56.062421: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 87326796 exceeds 10% of system memory.\n",
            "2020-04-22 14:35:02.312153: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 91726008 exceeds 10% of system memory.\n",
            "2020-04-22 14:35:02.740383: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 91726008 exceeds 10% of system memory.\n",
            "Traceback (most recent call last):\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n",
            "    target_list, run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\n",
            "  (0) Invalid argument: Cannot add tensor to the batch: number of elements does not match. Shapes are: [tensor]: [474,1024,3], [batch]: [600,626,3]\n",
            "\t [[{{node IteratorGetNext}}]]\n",
            "\t [[ToAbsoluteCoordinates_7/Assert/AssertGuard/Assert/data_0/_6821]]\n",
            "  (1) Invalid argument: Cannot add tensor to the batch: number of elements does not match. Shapes are: [tensor]: [474,1024,3], [batch]: [600,626,3]\n",
            "\t [[{{node IteratorGetNext}}]]\n",
            "0 successful operations.\n",
            "0 derived errors ignored.\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/models/research/object_detection/model_main.py\", line 109, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/models/research/object_detection/model_main.py\", line 105, in main\n",
            "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\n",
            "    return executor.run()\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/training.py\", line 613, in run\n",
            "    return self.run_local()\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\n",
            "    saving_listeners=saving_listeners)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n",
            "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n",
            "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1195, in _train_model_default\n",
            "    saving_listeners)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1494, in _train_with_estimator_spec\n",
            "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 754, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 1259, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 1360, in run\n",
            "    raise six.reraise(*original_exc_info)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/six.py\", line 693, in reraise\n",
            "    raise value\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 1345, in run\n",
            "    return self._sess.run(*args, **kwargs)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 1418, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/training/monitored_session.py\", line 1176, in run\n",
            "    return self._sess.run(*args, **kwargs)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 956, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1180, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\", line 1384, in _do_call\n",
            "    raise type(e)(node_def, op, message)\n",
            "tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\n",
            "  (0) Invalid argument: Cannot add tensor to the batch: number of elements does not match. Shapes are: [tensor]: [474,1024,3], [batch]: [600,626,3]\n",
            "\t [[node IteratorGetNext (defined at tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py:1748) ]]\n",
            "\t [[ToAbsoluteCoordinates_7/Assert/AssertGuard/Assert/data_0/_6821]]\n",
            "  (1) Invalid argument: Cannot add tensor to the batch: number of elements does not match. Shapes are: [tensor]: [474,1024,3], [batch]: [600,626,3]\n",
            "\t [[node IteratorGetNext (defined at tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py:1748) ]]\n",
            "0 successful operations.\n",
            "0 derived errors ignored.\n",
            "\n",
            "Original stack trace for 'IteratorGetNext':\n",
            "  File \"content/models/research/object_detection/model_main.py\", line 109, in <module>\n",
            "    tf.app.run()\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
            "    _run_main(main, args)\n",
            "  File \"usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"content/models/research/object_detection/model_main.py\", line 105, in main\n",
            "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\n",
            "    return executor.run()\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/training.py\", line 613, in run\n",
            "    return self.run_local()\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\n",
            "    saving_listeners=saving_listeners)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n",
            "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n",
            "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1188, in _train_model_default\n",
            "    input_fn, ModeKeys.TRAIN))\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/estimator.py\", line 1025, in _get_features_and_labels_from_input_fn\n",
            "    self._call_input_fn(input_fn, mode))\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_estimator/python/estimator/util.py\", line 65, in parse_input_fn_result\n",
            "    result = iterator.get_next()\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/data/ops/iterator_ops.py\", line 426, in get_next\n",
            "    name=name)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/gen_dataset_ops.py\", line 2518, in iterator_get_next\n",
            "    output_shapes=output_shapes, name=name)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n",
            "    op_def=op_def)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n",
            "    attrs, op_def, compute_device)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n",
            "    op_def=op_def)\n",
            "  File \"tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n",
            "    self._traceback = tf_stack.extract_stack()\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1beh9ceRqlK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c9349381-47b4-4b21-9359-1def8966b303"
      },
      "source": [
        "!ls {model_dir}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t\t\t     model.ckpt-0.meta\n",
            "events.out.tfevents.1587563045.03b286201b54  model.ckpt-539.data-00000-of-00001\n",
            "graph.pbtxt\t\t\t\t     model.ckpt-539.index\n",
            "model.ckpt-0.data-00000-of-00001\t     model.ckpt-539.meta\n",
            "model.ckpt-0.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBLspw5JUVvf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3e5cc5fd-5eec-42f8-fb06-cb3ba35c6b76"
      },
      "source": [
        "%cd model_dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'model_dir'\n",
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0tAhUiSUvy4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0dd4d122-8b76-4413-ccf3-e4367775f66c"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "output_directory = './fine_tuned_model'\n",
        "\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n",
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training/model.ckpt-462\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_inference_graph.py:162: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0422 13:22:54.531065 140511395833728 module_wrapper.py:139] From /content/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0422 13:22:54.534145 140511395833728 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0422 13:22:54.534443 140511395833728 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:2689: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W0422 13:22:54.574556 140511395833728 module_wrapper.py:139] From /content/models/research/object_detection/core/preprocessor.py:2689: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:168: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0422 13:22:54.620206 140511395833728 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:168: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0422 13:22:54.629096 140511395833728 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0422 13:22:54.632276 140511395833728 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "W0422 13:22:57.585297 140511395833728 module_wrapper.py:139] From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0422 13:22:57.591527 140511395833728 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:558: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "W0422 13:22:57.591888 140511395833728 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:558: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0422 13:22:57.604686 140511395833728 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0422 13:22:57.605047 140511395833728 module_wrapper.py:139] From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0422 13:22:57.605167 140511395833728 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/box_list_ops.py:141: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0422 13:22:57.656165 140511395833728 deprecation.py:323] From /content/models/research/object_detection/core/box_list_ops.py:141: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:191: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W0422 13:22:58.184009 140511395833728 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:191: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0422 13:22:58.184420 140511395833728 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0422 13:22:58.457487 140511395833728 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/ops.py:766: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "W0422 13:22:58.601638 140511395833728 deprecation.py:506] From /content/models/research/object_detection/utils/ops.py:766: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "W0422 13:22:59.443783 140511395833728 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "W0422 13:22:59.532512 140511395833728 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0422 13:22:59.532757 140511395833728 deprecation.py:323] From /content/models/research/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:415: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0422 13:22:59.535523 140511395833728 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:415: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W0422 13:22:59.535701 140511395833728 deprecation.py:323] From /content/models/research/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "W0422 13:22:59.536685 140511395833728 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "241 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/64.29m params)\n",
            "  Conv (--/4.72m params)\n",
            "    Conv/biases (512, 512/512 params)\n",
            "    Conv/weights (3x3x1024x512, 4.72m/4.72m params)\n",
            "  FirstStageBoxPredictor (--/36.94k params)\n",
            "    FirstStageBoxPredictor/BoxEncodingPredictor (--/24.62k params)\n",
            "      FirstStageBoxPredictor/BoxEncodingPredictor/biases (48, 48/48 params)\n",
            "      FirstStageBoxPredictor/BoxEncodingPredictor/weights (1x1x512x48, 24.58k/24.58k params)\n",
            "    FirstStageBoxPredictor/ClassPredictor (--/12.31k params)\n",
            "      FirstStageBoxPredictor/ClassPredictor/biases (24, 24/24 params)\n",
            "      FirstStageBoxPredictor/ClassPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "  FirstStageFeatureExtractor (--/42.39m params)\n",
            "    FirstStageFeatureExtractor/resnet_v1_101 (--/42.39m params)\n",
            "      FirstStageFeatureExtractor/resnet_v1_101/block1 (--/212.99k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1 (--/73.73k params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv1 (--/4.10k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/weights (1x1x64x64, 4.10k/4.10k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv2 (--/36.86k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/weights (3x3x64x64, 36.86k/36.86k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv3 (--/16.38k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/weights (1x1x64x256, 16.38k/16.38k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut (--/16.38k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/weights (1x1x64x256, 16.38k/16.38k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2 (--/69.63k params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1 (--/69.63k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1 (--/16.38k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv2 (--/36.86k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/weights (3x3x64x64, 36.86k/36.86k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv3 (--/16.38k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/weights (1x1x64x256, 16.38k/16.38k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3 (--/69.63k params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1 (--/69.63k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv1 (--/16.38k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv2 (--/36.86k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/weights (3x3x64x64, 36.86k/36.86k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv3 (--/16.38k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/weights (1x1x64x256, 16.38k/16.38k params)\n",
            "      FirstStageFeatureExtractor/resnet_v1_101/block2 (--/1.21m params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1 (--/376.83k params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1 (--/376.83k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv1 (--/32.77k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/weights (1x1x256x128, 32.77k/32.77k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv2 (--/147.46k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv3 (--/65.54k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/weights (1x1x128x512, 65.54k/65.54k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut (--/131.07k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/weights (1x1x256x512, 131.07k/131.07k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2 (--/278.53k params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1 (--/278.53k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv1 (--/65.54k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/weights (1x1x512x128, 65.54k/65.54k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv2 (--/147.46k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv3 (--/65.54k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/weights (1x1x128x512, 65.54k/65.54k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3 (--/278.53k params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1 (--/278.53k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv1 (--/65.54k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/weights (1x1x512x128, 65.54k/65.54k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv2 (--/147.46k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv3 (--/65.54k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/weights (1x1x128x512, 65.54k/65.54k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4 (--/278.53k params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1 (--/278.53k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv1 (--/65.54k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/weights (1x1x512x128, 65.54k/65.54k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv2 (--/147.46k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv3 (--/65.54k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/weights (1x1x128x512, 65.54k/65.54k params)\n",
            "      FirstStageFeatureExtractor/resnet_v1_101/block3 (--/26.02m params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1 (--/1.51m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1 (--/1.51m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv1 (--/131.07k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/weights (1x1x512x256, 131.07k/131.07k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut (--/524.29k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/weights (1x1x512x1024, 524.29k/524.29k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "      FirstStageFeatureExtractor/resnet_v1_101/block4 (--/14.94m params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1 (--/6.03m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1 (--/6.03m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1 (--/524.29k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/weights (1x1x1024x512, 524.29k/524.29k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2 (--/2.36m params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3 (--/1.05m params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut (--/2.10m params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/weights (1x1x1024x2048, 2.10m/2.10m params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2 (--/4.46m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1 (--/4.46m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1 (--/1.05m params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/weights (1x1x2048x512, 1.05m/1.05m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2 (--/2.36m params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3 (--/1.05m params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3 (--/4.46m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1 (--/4.46m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1 (--/1.05m params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/weights (1x1x2048x512, 1.05m/1.05m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2 (--/2.36m params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3 (--/1.05m params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n",
            "      FirstStageFeatureExtractor/resnet_v1_101/conv1 (--/9.41k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/conv1/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/conv1/weights (7x7x3x64, 9.41k/9.41k params)\n",
            "  SecondStageBoxPredictor (--/2.20m params)\n",
            "    SecondStageBoxPredictor/class_predictions (--/27.68k params)\n",
            "      SecondStageBoxPredictor/class_predictions/biases (27, 27/27 params)\n",
            "      SecondStageBoxPredictor/class_predictions/weights (1x1x1024x27, 27.65k/27.65k params)\n",
            "    SecondStageBoxPredictor/reduce_depth (--/2.10m params)\n",
            "      SecondStageBoxPredictor/reduce_depth/biases (1024, 1.02k/1.02k params)\n",
            "      SecondStageBoxPredictor/reduce_depth/weights (1x1x2048x1024, 2.10m/2.10m params)\n",
            "    SecondStageBoxPredictor/refined_locations (--/73.80k params)\n",
            "      SecondStageBoxPredictor/refined_locations/biases (72, 72/72 params)\n",
            "      SecondStageBoxPredictor/refined_locations/weights (1x1x1024x72, 73.73k/73.73k params)\n",
            "  SecondStageFeatureExtractor (--/14.94m params)\n",
            "    SecondStageFeatureExtractor/resnet_v1_101 (--/14.94m params)\n",
            "      SecondStageFeatureExtractor/resnet_v1_101/block4 (--/14.94m params)\n",
            "        SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1 (--/6.03m params)\n",
            "          SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1 (--/6.03m params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1 (--/524.29k params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/weights (1x1x1024x512, 524.29k/524.29k params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2 (--/2.36m params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3 (--/1.05m params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut (--/2.10m params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/weights (1x1x1024x2048, 2.10m/2.10m params)\n",
            "        SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2 (--/4.46m params)\n",
            "          SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1 (--/4.46m params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1 (--/1.05m params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/weights (1x1x2048x512, 1.05m/1.05m params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2 (--/2.36m params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3 (--/1.05m params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n",
            "        SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3 (--/4.46m params)\n",
            "          SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1 (--/4.46m params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1 (--/1.05m params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/weights (1x1x2048x512, 1.05m/1.05m params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2 (--/2.36m params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3 (--/1.05m params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n",
            "\n",
            "======================End of Report==========================\n",
            "241 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/1.23m flops)\n",
            "  SecondStageBoxPredictor/map/while/AddN (691.20k/691.20k flops)\n",
            "  SecondStageBoxPredictor/map_1/while/AddN (259.20k/259.20k flops)\n",
            "  SecondStageBoxPredictor/map/while/Mean (86.40k/86.40k flops)\n",
            "  SecondStageBoxPredictor/map/while/truediv_12 (86.40k/86.40k flops)\n",
            "  SecondStageBoxPredictor/map_1/while/truediv_12 (32.40k/32.40k flops)\n",
            "  SecondStageBoxPredictor/map_1/while/Mean (32.40k/32.40k flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_21 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_11 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_13 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_15 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_16 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_17 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_33 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_32 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_18 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_19 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_2 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_20 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_29 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_22 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_23 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_31 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_30 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_24 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_25 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_3 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_26 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_27 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_28 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/truediv_2 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/sub_2 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/sub_3 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/sub_4 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/sub_5 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/sub_6 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/sub_7 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/sub_8 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/sub_9 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/truediv (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/truediv_1 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/truediv_10 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/truediv_11 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_12 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/truediv_3 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/truediv_4 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/truediv_5 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/truediv_6 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/truediv_7 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/truediv_8 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/truediv_9 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_1 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_10 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_34 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_3 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/truediv_5 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/truediv_6 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/truediv_7 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/truediv_8 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/truediv_9 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_1 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_2 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_1 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_2 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/truediv_4 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
            "  map_2/while/mul (300/300 flops)\n",
            "  map_2/while/mul_1 (300/300 flops)\n",
            "  map_2/while/mul_2 (300/300 flops)\n",
            "  map_2/while/mul_3 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/sub_3 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_35 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_4 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_5 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_6 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_7 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_8 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_9 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/sub (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/sub_1 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/sub_10 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/sub_11 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/sub_2 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/mul_14 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/sub_4 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/sub_5 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/sub_6 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/sub_7 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/sub_8 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/sub_9 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/truediv (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/truediv_1 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/truediv_10 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/truediv_11 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/truediv_2 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/truediv_3 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_17 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_25 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_24 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/sub_11 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_23 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_22 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_21 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_20 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_2 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_19 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_18 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/sub_10 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_16 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_15 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_14 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_13 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_12 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_11 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_10 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_1 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_27 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/sub_1 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/sub (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_9 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_8 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_7 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_6 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_5 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_4 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_35 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_33 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_32 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_31 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_30 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_3 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_29 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_26 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_28 (300/300 flops)\n",
            "  SecondStageBoxPredictor/map/while/mul_34 (300/300 flops)\n",
            "  GridAnchorGenerator/truediv (12/12 flops)\n",
            "  GridAnchorGenerator/mul_2 (12/12 flops)\n",
            "  GridAnchorGenerator/mul_1 (12/12 flops)\n",
            "  GridAnchorGenerator/mul (12/12 flops)\n",
            "  FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/required_space_to_batch_paddings/sub (2/2 flops)\n",
            "  FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/required_space_to_batch_paddings/sub (2/2 flops)\n",
            "  FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/required_space_to_batch_paddings/sub (2/2 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  map/while/Less_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  map_2/while/Less_1 (1/1 flops)\n",
            "  map_2/while/Less (1/1 flops)\n",
            "  map_1/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  map_1/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  map_1/while/Less_1 (1/1 flops)\n",
            "  map_1/while/Less (1/1 flops)\n",
            "  map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/Less_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/Less (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/Minimum (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
            "  FirstStageFeatureExtractor/GreaterEqual (1/1 flops)\n",
            "  FirstStageFeatureExtractor/GreaterEqual_1 (1/1 flops)\n",
            "  GridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
            "  GridAnchorGenerator/mul_7 (1/1 flops)\n",
            "  GridAnchorGenerator/mul_8 (1/1 flops)\n",
            "  GridAnchorGenerator/zeros/Less (1/1 flops)\n",
            "  Preprocessor/map/while/Less (1/1 flops)\n",
            "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/Less (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/mul (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/mul_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/truediv (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/truediv_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/Minimum (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv_1 (1/1 flops)\n",
            "  SecondStageBoxPredictor/map/while/Less (1/1 flops)\n",
            "  SecondStageBoxPredictor/map/while/Less_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/Less_1 (1/1 flops)\n",
            "  SecondStageBoxPredictor/map_1/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchGather/mul_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchGather/mul (1/1 flops)\n",
            "  SecondStageBoxPredictor/mul_1 (1/1 flops)\n",
            "  SecondStageBoxPredictor/mul (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0422 13:23:01.305159 140511395833728 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:342: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0422 13:23:02.588121 140511395833728 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:342: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-04-22 13:23:02.591757: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-04-22 13:23:02.613771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-22 13:23:02.614319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-04-22 13:23:02.619623: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-22 13:23:02.635370: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-04-22 13:23:02.641129: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-04-22 13:23:02.648556: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-04-22 13:23:02.668092: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-04-22 13:23:02.684517: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-04-22 13:23:02.709039: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-22 13:23:02.709170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-22 13:23:02.709844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-22 13:23:02.710379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-04-22 13:23:02.710788: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
            "2020-04-22 13:23:02.715516: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000179999 Hz\n",
            "2020-04-22 13:23:02.715695: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x22ab2c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-04-22 13:23:02.715722: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-04-22 13:23:02.807866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-22 13:23:02.808548: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x22aaf40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-04-22 13:23:02.808581: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-04-22 13:23:02.808762: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-22 13:23:02.809273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-04-22 13:23:02.809393: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-22 13:23:02.809424: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-04-22 13:23:02.809444: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-04-22 13:23:02.809463: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-04-22 13:23:02.809481: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-04-22 13:23:02.809499: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-04-22 13:23:02.809518: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-22 13:23:02.809588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-22 13:23:02.810124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-22 13:23:02.810626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-04-22 13:23:02.810702: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-22 13:23:02.811845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-04-22 13:23:02.811872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-04-22 13:23:02.811882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-04-22 13:23:02.811996: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-22 13:23:02.812556: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-22 13:23:02.813046: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-04-22 13:23:02.813091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-462\n",
            "I0422 13:23:02.815028 140511395833728 saver.py:1284] Restoring parameters from training/model.ckpt-462\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0422 13:23:05.926909 140511395833728 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2020-04-22 13:23:06.708529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-22 13:23:06.709172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-04-22 13:23:06.709261: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-22 13:23:06.709294: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-04-22 13:23:06.709341: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-04-22 13:23:06.709369: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-04-22 13:23:06.709392: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-04-22 13:23:06.709415: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-04-22 13:23:06.709437: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-22 13:23:06.709529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-22 13:23:06.710149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-22 13:23:06.710706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-04-22 13:23:06.710749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-04-22 13:23:06.710765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-04-22 13:23:06.710775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-04-22 13:23:06.710873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-22 13:23:06.711494: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-22 13:23:06.712057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-462\n",
            "I0422 13:23:06.713205 140511395833728 saver.py:1284] Restoring parameters from training/model.ckpt-462\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0422 13:23:07.903278 140511395833728 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0422 13:23:07.903600 140511395833728 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 532 variables.\n",
            "I0422 13:23:08.695549 140511395833728 graph_util_impl.py:334] Froze 532 variables.\n",
            "INFO:tensorflow:Converted 532 variables to const ops.\n",
            "I0422 13:23:08.975235 140511395833728 graph_util_impl.py:394] Converted 532 variables to const ops.\n",
            "2020-04-22 13:23:09.578415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-22 13:23:09.579058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-04-22 13:23:09.579142: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-22 13:23:09.579167: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-04-22 13:23:09.579189: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-04-22 13:23:09.579213: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-04-22 13:23:09.579234: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-04-22 13:23:09.579253: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-04-22 13:23:09.579274: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-22 13:23:09.579379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-22 13:23:09.580005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-22 13:23:09.580541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-04-22 13:23:09.580583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-04-22 13:23:09.580598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-04-22 13:23:09.580608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-04-22 13:23:09.580700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-22 13:23:09.581279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-22 13:23:09.581871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "W0422 13:23:10.416682 140511395833728 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:309: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0422 13:23:10.417162 140511395833728 deprecation.py:323] From /content/models/research/object_detection/exporter.py:309: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:315: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
            "\n",
            "W0422 13:23:10.417663 140511395833728 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:315: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:318: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
            "\n",
            "W0422 13:23:10.417850 140511395833728 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:318: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:323: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
            "\n",
            "W0422 13:23:10.418063 140511395833728 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:323: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:325: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
            "\n",
            "W0422 13:23:10.418194 140511395833728 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:325: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
            "\n",
            "INFO:tensorflow:No assets to save.\n",
            "I0422 13:23:10.418488 140511395833728 builder_impl.py:640] No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0422 13:23:10.418586 140511395833728 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: ./fine_tuned_model/saved_model/saved_model.pb\n",
            "I0422 13:23:11.318974 140511395833728 builder_impl.py:425] SavedModel written to: ./fine_tuned_model/saved_model/saved_model.pb\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0422 13:23:11.444329 140511395833728 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "INFO:tensorflow:Writing pipeline config file to ./fine_tuned_model/pipeline.config\n",
            "I0422 13:23:11.444622 140511395833728 config_util.py:190] Writing pipeline config file to ./fine_tuned_model/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRF4Y846e-wx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "dbc55ffc-f415-4e30-b66e-5fd07c2d9618"
      },
      "source": [
        "!ls {output_directory}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t\tmodel.ckpt.index  saved_model\n",
            "frozen_inference_graph.pb\tmodel.ckpt.meta\n",
            "model.ckpt.data-00000-of-00001\tpipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu1xNOaJfYmP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "074f136f-ecdc-47cc-96ef-8182c6303b6e"
      },
      "source": [
        "output_directory"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./fine_tuned_model'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxPPk-iHfMUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n",
        "assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTN-84BjfOtc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('/content/models/research/fine_tuned_model/saved_model/saved_model.pb')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05gmAk38iWQz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a40af957-cd64-4f05-a861-422a8edbce88"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h90pOy8XqFKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "#%tensorflow_version 1.13.1\n",
        "import cv2\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append('/content/models/research/object_detection')\n",
        "\n",
        "\n",
        "# ## Object detection imports\n",
        "# Here are the imports from the object detection module.\n",
        "\n",
        "# In[3]:\n",
        "\n",
        "from utils import label_map_util\n",
        "\n",
        "from utils import visualization_utils as vis_util\n",
        "\n",
        "\n",
        "# # Model preparation \n",
        "\n",
        "# ## Variables\n",
        "# \n",
        "# Any model exported using the `export_inference_graph.py` tool can be loaded here simply by changing `PATH_TO_CKPT` to point to a new .pb file.  \n",
        "# \n",
        "# By default we use an \"SSD with Mobilenet\" model here. See the [detection model zoo](https://github.com/tensorflow/models/blob/master/object_detection/g3doc/detection_model_zoo.md) for a list of other models that can be run out-of-the-box with varying speeds and accuracies.\n",
        "\n",
        "# In[4]:\n",
        "\n",
        "# What model to download.\n",
        "#MODEL_NAME = 'ssd_mobilenet_v1_coco_11_06_2017'\n",
        "#MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
        "#DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "MODEL_NAME='mask'\n",
        "PATH_TO_CKPT = '/content/models/research/fine_tuned_model/frozen_inference_graph.pb'\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = '/content/drive/My Drive/data/object-detection.pbtxt'\n",
        "\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "\n",
        "# ## Download Model\n",
        "\n",
        "# In[5]:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ## Load a (frozen) Tensorflow model into memory.\n",
        "\n",
        "# In[6]:\n",
        "\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def =tf.compat.v1.GraphDef()\n",
        "  with tf.io.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "\n",
        "# ## Loading label map\n",
        "# Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine\n",
        "\n",
        "# In[7]:\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZViIsNUXzn6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cap = cv2.VideoCapture('/content/drive/My Drive/2020-04-22_18-03-18.mp4')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of0amDcV4mYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "\n",
        "# ## Helper code\n",
        "\n",
        "# In[8]:\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "\n",
        "# # Detection\n",
        "\n",
        "# In[9]:\n",
        "\n",
        "# For the sake of simplicity we will use only 2 images:\n",
        "# image1.jpg\n",
        "# image2.jpg\n",
        "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
        "\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)\n",
        "\n",
        "\n",
        "# In[10]:\n",
        "i=1\n",
        "with detection_graph.as_default():\n",
        "  with tf.Session(graph=detection_graph) as sess:\n",
        "    while True:\n",
        "      ret, image_np = cap.read()\n",
        "      # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "      image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "      image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "      # Each box represents a part of the image where a particular object was detected.\n",
        "      boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "      # Each score represent how level of confidence for each of the objects.\n",
        "      # Score is shown on the result image, together with the class label.\n",
        "      scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "      classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "      num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "      # Actual detection.\n",
        "      (boxes, scores, classes, num_detections) = sess.run(\n",
        "          [boxes, scores, classes, num_detections],\n",
        "          feed_dict={image_tensor: image_np_expanded})\n",
        "      # Visualization of the results of a detection.\n",
        "      vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "          image_np,\n",
        "          np.squeeze(boxes),\n",
        "          np.squeeze(classes).astype(np.int32),\n",
        "          np.squeeze(scores),\n",
        "          category_index,\n",
        "          use_normalized_coordinates=True,\n",
        "          line_thickness=8)\n",
        "      print(i)\n",
        "      i=i+1\n",
        "      cv2.imshow('object detec cv2.resize(image_np, (800,600)))\n",
        "      if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "        cv2.destroyAllWindows()\n",
        "        break\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF5Oze4bEA1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}